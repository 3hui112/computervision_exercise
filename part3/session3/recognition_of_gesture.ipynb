{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54fyX0_J343B"
      },
      "source": [
        "# Recognition of gestures and actions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVW83JLq5IFQ"
      },
      "source": [
        "## Detecting body points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBA5Bn1Lj-En"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nA-thC945KSJ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnHBxHV9lmS1"
      },
      "source": [
        "### Loading the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C0Pinynf5XWg"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D8KUTJEz52J9"
      },
      "outputs": [],
      "source": [
        "#image = cv2.imread('/content/drive/MyDrive/vision/megan.jpg')\n",
        "image = cv2.imread('images/megan.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wLacyE5J6AwD"
      },
      "outputs": [],
      "source": [
        "cv2.imshow('megan.jpg', image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gx33J0or6MGN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((337, 600, 3), 606600)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image.shape, image.shape[0] * image.shape[1] * 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UNAahris7pwG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VcKAQdBl6pxk"
      },
      "outputs": [],
      "source": [
        "# Mean subtraction: https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/\n",
        "image_blob = cv2.dnn.blobFromImage(image = image, scalefactor = 1.0 / 255,\n",
        "                                   size = (image.shape[1], image.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JsnhtKz87moW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(numpy.ndarray, (1, 3, 337, 600))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(image_blob), image_blob.shape # batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwtmRa6ToQIc"
      },
      "source": [
        "### Loading the pre-trained neural network\n",
        "\n",
        "- Caffe Deep Learning framework: https://caffe.berkeleyvision.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "o1z1vxJt9qSQ"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/dnn/src/caffe/caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"pose_iter_160000.caffemodel\" in function 'ReadProtoFromBinaryFile'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# network = cv2.dnn.readNetFromCaffe('/content/drive/MyDrive/Weights/pose_deploy_linevec_faster_4_stages.prototxt',\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#                                   '/content/drive/MyDrive/Weights/pose_iter_160000.caffemodel')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# network = cv2.dnn.readNetFromCaffe('/Weights/pose_deploy_linevec_faster_4_stages.prototxt', '/Weights/pose_iter_160000.caffemodel')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# network = cv2.dnn.readNet('/Weights/pose_deploy_linevec_faster_4_stages.prototxt', '/Weights/pose_iter_160000.caffemodel')\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNetFromCaffe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpose-master/models/pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpose_iter_160000.caffemodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/dnn/src/caffe/caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"pose_iter_160000.caffemodel\" in function 'ReadProtoFromBinaryFile'\n"
          ]
        }
      ],
      "source": [
        "# network = cv2.dnn.readNetFromCaffe('/content/drive/MyDrive/Weights/pose_deploy_linevec_faster_4_stages.prototxt',\n",
        "#                                   '/content/drive/MyDrive/Weights/pose_iter_160000.caffemodel')\n",
        "\n",
        "network = cv2.dnn.readNetFromCaffe('openpose-master/models/pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt', 'pose_iter_160000.caffemodel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXelzzcF-O38"
      },
      "outputs": [],
      "source": [
        "network.getLayerNames()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL9bNzAV-j4q"
      },
      "outputs": [],
      "source": [
        "len(network.getLayerNames())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzXLIBMHsbgX"
      },
      "source": [
        "### Predicting body points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uLA2eLFm_22d"
      },
      "outputs": [],
      "source": [
        "network.setInput(image_blob)\n",
        "output = network.forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAUfKDPhAbRS"
      },
      "outputs": [],
      "source": [
        "# 44 -> related to the points that were detected\n",
        "# (43, 75) -> information about the location\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pHiQam18A7Mm"
      },
      "outputs": [],
      "source": [
        "position_width = output.shape[3]\n",
        "position_heigth = output.shape[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWSIBlDhBaTr"
      },
      "outputs": [],
      "source": [
        "position_width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kvMV7ubE7oP"
      },
      "outputs": [],
      "source": [
        "(image.shape[1] * 28) / 75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-aJrQjWZBnX1"
      },
      "outputs": [],
      "source": [
        "# minMaxLoc: https://docs.opencv.org/master/d2/de8/group__core__array.html#gab473bf2eb6d14ff97e89b355dac20707\n",
        "num_points = 15\n",
        "points = []\n",
        "threshold = 0.1\n",
        "for i in range(num_points):\n",
        "  #print(i)\n",
        "  confidence_map = output[0, i, :, :]\n",
        "  #print(confidence_map) # candidate points\n",
        "  #print(len(confidence_map))\n",
        "  _, confidence, _, point = cv2.minMaxLoc(confidence_map)\n",
        "  #print(confidence)\n",
        "  #print(point)\n",
        "\n",
        "  x = int((image.shape[1] * point[0]) / position_width)\n",
        "  y = int((image.shape[0] * point[1]) / position_heigth)\n",
        "  #print(x,y)\n",
        "  if confidence > threshold:\n",
        "    cv2.circle(image, (x, y), 5, (0,255,0), thickness = -1)\n",
        "    cv2.putText(image, '{}'.format(i), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255))\n",
        "    points.append((x,y))\n",
        "  else:\n",
        "    points.append(None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpbEpC9bGCtu"
      },
      "outputs": [],
      "source": [
        "points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvUhzcq2GGPU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "E93ImpQOH4vS"
      },
      "outputs": [],
      "source": [
        "point_connections = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7],[1,14],\n",
        "                     [14,8], [8,9], [9,10], [14,11], [11,12], [12,13]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7mIf2ZkIWtv"
      },
      "outputs": [],
      "source": [
        "point_connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Siikl1gfIb5h"
      },
      "outputs": [],
      "source": [
        "for connection in point_connections:\n",
        "  #print(connection)\n",
        "  partA = connection[0]\n",
        "  partB = connection[1]\n",
        "  #print(partA, partB)\n",
        "  if points[partA] and points[partB]:\n",
        "    cv2.line(image, points[partA], points[partB], (255,0,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aaYa09EJA3Q"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzepqn_f5bME"
      },
      "source": [
        "## Detecting movements (arms above the head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulK3kP3d5kJh"
      },
      "source": [
        "### Arms above the head in videos\n",
        "\n",
        "- VideoWriter_fourcc: https://www.programcreek.com/python/example/89348/cv2.VideoWriter_fourcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EqIAgimvRnz0"
      },
      "outputs": [],
      "source": [
        "# video = '/content/drive/MyDrive/vision/video/gesture1.mp4'\n",
        "capture = cv2.VideoCapture(video)\n",
        "connected, frame = capture.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpRGXxKgR2cP"
      },
      "outputs": [],
      "source": [
        "connected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osARd8RrR7le"
      },
      "outputs": [],
      "source": [
        "frame.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4WrxQNFbSBZi"
      },
      "outputs": [],
      "source": [
        "# result = '/content/drive/MyDrive/vision/Video/gesture1_result.mp4'\n",
        "save_video = cv2.VideoWriter(result, cv2.VideoWriter_fourcc(*'XVID'),  10, (frame.shape[1], frame.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyHWEzrZoCvl"
      },
      "source": [
        "### Arms above the head in images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjV_4ufMKws_"
      },
      "outputs": [],
      "source": [
        "# image2 = cv2.imread('/content/drive/MyDrive/vision/images/player.jpg')\n",
        "cv2_imshow(image2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTBWn_j6LQek"
      },
      "outputs": [],
      "source": [
        "# image2 = cv2.imread('/content/drive/MyDrive/vision/images/player.jpg')\n",
        "image_blob2 = cv2.dnn.blobFromImage(image = image2, scalefactor = 1.0 / 255, size = (image2.shape[1], image2.shape[0]))\n",
        "network.setInput(image_blob2)\n",
        "output2 = network.forward()\n",
        "position_width = output2.shape[3]\n",
        "position_height = output2.shape[2]\n",
        "num_points = 15\n",
        "points = []\n",
        "threshold = 0.1\n",
        "for i in range(num_points):\n",
        "  confidence_map = output2[0, i, :, :]\n",
        "  _, confidence, _, point = cv2.minMaxLoc(confidence_map)\n",
        "  x = int((image2.shape[1] * point[0]) / position_width)\n",
        "  y = int((image2.shape[0] * point[1]) / position_height)\n",
        "\n",
        "  if confidence > threshold:\n",
        "    cv2.circle(image2, (x, y), 3, (0,255,0), thickness = -1)\n",
        "    cv2.putText(image2, \"{}\".format(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, .3, (0, 0, 255))\n",
        "    cv2.putText(image2, '{}-{}'.format(point[0], point[1]), (x, y + 10), cv2.FONT_HERSHEY_SIMPLEX, .5, (255,0,255))\n",
        "    points.append((x, y))\n",
        "  else:\n",
        "    points.append(None)\n",
        "\n",
        "plt.figure(figsize = [14,10])\n",
        "plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MqrtF1gFOdAE"
      },
      "outputs": [],
      "source": [
        "def verify_arms_up(points):\n",
        "  head, right_wrist, left_wrist = 0, 0, 0\n",
        "  for i, point in enumerate(points):\n",
        "    #print(i, point)\n",
        "    if i == 0:\n",
        "      head = point[1]\n",
        "    elif i == 4:\n",
        "      right_wrist = point[1]\n",
        "    elif i == 7:\n",
        "      left_wrist = point[1]\n",
        "\n",
        "  #print(head, right_wrist, left_wrist)\n",
        "  if right_wrist < head and left_wrist < head:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBCdQJAiOsp_"
      },
      "outputs": [],
      "source": [
        "verify_arms_up(points)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
